{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이썬 머신러닝\n",
    "# 과대적합 과소적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 개념\n",
    "- 지도학습(supervised learning)은 샘플 데이터가 있고, 각 샘플마다 **레이블**(타겟값 혹은 목표값)이 지정되어 있는 학습 방법이다.\n",
    "- 기존에 가지고 있는 데이터와 레이블을 가지고 학습을 하고 나면, 새로운 샘플 데이터에 대해 레이블을 예측할 수 있다.\n",
    "- 레이블이 연속적이거나 실수값인 경우는 **회귀(regression)** 문제가 되고, 레이블이 예/아니오, 고양이/개/원숭이 와 같이 여러 클래스 중에 하나인 경우를 **분류(classification)** 문제라고 한다.\n",
    "- 분류의 경우에 예/아니오 와 같이 둘 중에 하나를 예측하는 것을 **이진 분류** 라고 하고, 고양이/개/원숭이 와 같이 셋 이상의 클래스를 구분하는 것을 **다중 분류** 라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중요한 것은 새로운 데이터에 대해 잘 예측하는 것이다\n",
    "- 주어진 데이터에 대해 잘 들어맞는 아무리 훌륭한 예측 모델을 만들었다 하더라도, 새로운 데이터에 대한 예측 능력이 떨어진다면 아무런 의미가 없게 된다.\n",
    "- 머신러닝은 기본적으로 주어진 데이터와 새로운 데이터가 비슷한 패턴을 가질 것이라는 가정에 기반하고 있다. 다만 그렇게 되려면 주어진 데이터가 발생 가능한 모든 데이터를 대표할 수 있는 샘플들로 이루어져야 할 것이다. 하지만 이것은 현실적으로 불가능하다.\n",
    "- 이러한 문제는 주어진 데이터가 과연 **일반성**을 가지는가 라는 질문이 된다. 주어진 데이터가 일반성을 가지기 위한 가장 좋은 방법은 데이터를 아주 많이 확보하는 것이다. 발생 가능한 샘플 수가 10,000개 인데, 7,000개 정도의 데이터를 확보했다면 아주 정확한 모델을 만들 수 있는 것은 자명하다. 하지만 현실적으로 충분한 데이터를 확보하는 것은 머신러닝에서 가장 어려운 문제이다.\n",
    "- 또한 충분한 데이터를 확보했다 하더라도, 그 데이터 안에는 오류인 데이터도 있고 아주 드물게 발생하는 이상치도 포함되어 있을 수 밖에 없다. 그러므로 주어진 데이터가 많던 적던 너무 주어진 데이터에 딱 들어맞는 예측모델을 만드는 것은 예측 능력을 떨어트릴 수 있다.\n",
    "- 이와 같이, 너무 지나치게 훈련 데이터에 치우친 복잡한 모델은 **과대적합(overfitting)** 되었다고 하고, 너무 지나치게 예측 모델을 단순하게 만들어 훈련 데이터의 특징을 제대로 나타내지 못할 때 **과소적합(underfitting)** 이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ch02_01.png\" align=\"left\" /> <img src=\"ch02_02.png\" /><br>\n",
    "<p style=\"text-align: center;\">(출처 : wikipedia - overfitting)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그러므로 우리의 목표인 새로운 데이터에 대해 잘 예측하기 위해서는, 가능한 한 많은 데이터를 수집하되 너무 지나치게 확보한 데이터에 치우친 복잡한 예측모델을 만들지 않고 최대한 일반화 할 수 있는 예측모델을 만들 수 있는 능력을 가져야 한다.\n",
    "- 이를 위해 가장 좋은 방법은 충분한 데이터로 예측 모델을 만든 다음, 이 모델로 새로 발생하는 많은 데이터로 테스트를 해 보는 것이다. 하지만 새로운 데이터를 확보하는 것은 미래의 일이어서 많은 시간이 필요한 일이다. 그리고 대부분의 문제에 있어서는 즉시 결과를 볼 수 있어야 한다.\n",
    "- 이러한 과대적합/과소적합/일반성 의 문제를 해결하기 위해, 주어진 데이터에서 일부분은 **훈련세트** 로 하고, 나머지는 **테스트세트** 로 구성하여 훈련세트로 예측모델을 만든 다음에 테스트세트로 이 예측모델을 **검증** 하는 절차를 밟게 된다.\n",
    ">참고 : 앞으로 살펴볼 train_test_split() 함수가 이에 해당한다.\n",
    "\n",
    "- 이럴 경우 훈련세트는 과거에 발생해서 내가 확보하고 있는 데이터에 해당하고, 테스트세트는 미래에 새로 발생할 데이터에 해당한다고 하겠다.\n",
    "- 앞에서 충분한 데이터량을 확보하는 것이 가장 중요하다고 했다. 그렇다면 얼마나 충분한 데이터를 확보해야 할까? 이것은 해결하려는 문제마다 다르고 데이터의 성격에 따라 다르기 때문에 일반적인 답을 하기는 쉽지 않다. 그리고 중요한 연구 이슈이기도 하다. 한 가지 고려할 점은 속성(열)의 갯수가 늘어날 때 마다 그 만큼 데이터량도 늘어나야 한다는 점이다.\n",
    "- 결론적으로, 충분히 복잡하면서도 가능한 단순한 예측모델이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'target', 'target_names']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape, iris.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습데이터와 테스트데이터를 분리해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target,\n",
    "            test_size=20, shuffle=True, random_state=1) # 75% / 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112.5, 37.5, 37.5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "150*0.75, 150*0.25, 50*0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape # (112, 4)\n",
    "X_test.shape # (38, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42, 42, 46], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[y_train==2].shape\n",
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 4], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습용/테스트용 데이터 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "score = knn.score(X_test, y_test)\n",
    "pred_y = knn.predict(X_test)\n",
    "\n",
    "display(score, y_test, pred_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
